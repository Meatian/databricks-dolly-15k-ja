{"index":"6648","instruction":"クレジットスコアリングアルゴリズムによる2つの民族／性別グループ間の予測結果の違いは、データ収集プロセスやアルゴリズム自体のバイアスに該当するか？","input":"","output":"私は、クレジットスコアリングの結果の違いは、データの問題とアルゴリズムのバイアスの両方を構成していると主張する。まず、データセットのバイアスを検証してみましょう。私は、モデルそのものを、ある目的を果たすために出力を生成するブラックボックスと考えます。クレジットスコアリングの場合、目的はデフォルトリスク予測の精度、再現性、正確さです。このモデルは、外国人労働者、女性、若者を差別することはありません。しかし、モデルの学習対象となるデータセットには、社会的に構築されたバイアスが含まれています。例えば、社会通念上、女性は能力がない、外国人労働者は信用できない、若者は経験が浅いとされ、これらのグループの失業率の上昇や生活環境の悪化を招いている。その結果、ヒストリカル・デフォルトの可能性が高くなるのは、社会的ステレオタイプが生み出す悪循環よりも、人口統計学に関連した能力の差に起因する可能性が高い。ステレオタイプはデータセットに偏りを与え、その結果、アルゴリズムにも偏りが生じます。予測精度を最大化するという目標があれば、モデルはデータセットの「パターン」を学習し、予測アルゴリズムの一部として社会的に構築された差異を吸収していきます。アルゴリズムを責めることができるだろうか？- 結局のところ、モデルは「歴史」に制約され、歴史的に差別されてきた集団の可能性を想像する能力を持たないのです。基本的には、データ入力の歴史的・表現的バイアスによって引き起こされる「ゴミが入り、ゴミが出る」シナリオがある。\n\n一方、私は、結果の違いは依然としてアルゴリズムのバイアスを構成していると主張します。モデルが果たさなければならない目的や制約を（そもそも人間が定めたものであるにもかかわらず）「責める」ことはできると思うのです。上記のように、精度を評価指標とすると、過去のデータセットを基に構築された予測・予報アルゴリズム全体が、可能性を探したり社会規範を見極めたりすることなく、歴史を繰り返すことを意味します。精度を最大化するという目的自体がバイアスになるのだろうか。- 社会的に作られた神話（弱い女性、無謀な若者、外国人嫌い）によって作られ、また再定義される悪循環を見分けることができれば、ある種の社会的ステレオタイプを積極的に学習し伝播するモデルは、確かにそのバイアスを指摘されるべきです！しかし、私たちは、これらの目標を最適化するためにモデルをハードワイヤーで接続します。そして、測定基準に内在するバイアスに対処するために、私たち人間は、目標を修正し、適切な制約を加える責任があります。例えば、プログラミングの課題では、ある決定境界内の予測を拒否する緩和テクニックに出会います。積極的に拒否するような手法の他に、恵まれないグループの成長を促進するような制約を目的として加えることはできないでしょうか。このような制約がないと、結果の違いも目的指定の部分におけるアルゴリズム的な偏りになってしまうと言えるでしょう。","category":"creative_writing"}
