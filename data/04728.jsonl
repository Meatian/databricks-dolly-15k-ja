{"index":"4728","instruction":"提供された通路から、Kafkaの主要なAPIをリストアップしてください。コンマで区切ってください。","input":"Kafkaは、プロデューサーと呼ばれる任意の数のプロセスから送られてくるキーバリューメッセージを保存します。データは、異なる「トピック」内の異なる「パーティション」に分割することができます。パーティション内では、メッセージはオフセット（パーティション内のメッセージの位置）によって厳密に並べられ、タイムスタンプとともにインデックス付けされて保存されます。コンシューマー」と呼ばれる他のプロセスは、パーティションからメッセージを読み出すことができます。Kafkaはストリーム処理のために、Kafkaからデータを消費し、結果をKafkaに書き戻すJavaアプリケーションを書くことができるStreams APIを提供しています。Apache Kafkaは、Apache Apex、Apache Beam、Apache Flink、Apache Spark、Apache Storm、Apache NiFiなどの外部ストリーム処理システムとも連携しています。\n\nKafkaは1台以上のサーバー（ブローカーと呼ばれる）からなるクラスタ上で動作し、すべてのトピックのパーティションはクラスタノードに分散されます。さらに、パーティションは複数のブローカーにレプリケートされます。このアーキテクチャにより、Kafkaはフォールトトレラントな方法で大量のメッセージストリームを配信することができ、Java Message Service (JMS) や Advanced Message Queuing Protocol (AMQP) など、従来のメッセージングシステムの一部を置き換えることができました。0.11.0.0リリース以降、Kafkaはトランザクション書き込みを提供し、Streams APIを使用して正確な1回限りのストリーム処理を提供します。\n\nKafkaは2種類のトピックをサポートしています：通常のトピックとコンパクト化されたトピックの2種類をサポートしています。通常のトピックは、保持時間またはスペースバウンドを設定することができます。指定された保持時間よりも古いレコードがある場合、またはパーティションのスペースバウンドを超えた場合、Kafkaはストレージスペースを解放するために古いデータを削除することが許可されています。デフォルトでは、トピックは7日間の保持時間で構成されていますが、データを無期限に保存することも可能です。コンパクト化されたトピックでは、レコードは時間や空間の境界に基づいて期限切れになることはありません。その代わり、Kafkaは後のメッセージを同じキーを持つ古いメッセージの更新として扱い、キーごとに最新のメッセージを決して削除しないことを保証します。ユーザーは、特定のキーに対してNULL値を持ついわゆる墓石メッセージを書くことで、メッセージを完全に削除することができます。\n\nKafkaには、大きく分けて5つのAPIがあります：\n\nProducer API - アプリケーションがレコードのストリームを公開することを許可します。\nConsumer API - アプリケーションがトピックをサブスクライブし、レコードのストリームを処理することを許可します。\nConnector API - 既存のアプリケーションにトピックをリンクすることができる、再利用可能なプロデューサーおよびコンシューマーAPIを実行する。\nStreams API - 入力ストリームを出力に変換し、結果を生成するAPIです。\nAdmin API - Kafkaトピック、ブローカー、およびその他のKafkaオブジェクトを管理するために使用されます。\nコンシューマーAPIとプロデューサーAPIは、基盤となるメッセージングプロトコルによってKafkaのコア機能から切り離されます。これにより、KafkaにバンドルされているJava APIと同様に効率的な互換性のあるAPIレイヤーを任意のプログラミング言語で記述することができます。Apache Kafkaプロジェクトは、このようなサードパーティAPIのリストを管理しています。","output":"Producer API、Consumer API、Connector API、Streams API、Admin API","category":"information_extraction"}
