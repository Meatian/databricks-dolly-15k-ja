{"index":"10683","instruction":"1970年代、AI研究が衰退した要因は？","input":"T最初のAI冬 1974-1980\n1970年代、AIは批判と財政的な挫折にさらされていた。AI研究者は、自分たちが直面している問題の難しさを理解していなかったのである。同時に、コネクショニズム（ニューラルネット）の分野は、マーヴィン・ミンスキーによるパーセプトロンへの壊滅的な批判によって、10年間ほぼ完全に閉鎖された[102]。70年代後半のAIに対する世間の認識に対する困難にもかかわらず、論理プログラミング、常識的推論、その他多くの分野で新しいアイデアが探求された[103]。\n\n問題点\n70年代初頭、AIプログラムの能力は限られていた。最も印象的なものでさえ、解決すべき問題の些細なバージョンしか扱えず、すべてのプログラムはある意味で「おもちゃ」であった[104]。AI研究者は、1970年代に克服できないいくつかの基本的限界にぶつかり始めていたのである。これらの限界のいくつかは後の数十年で克服されることになるが、他の限界は今日に至るまでこの分野を苦しめている[105]。\n\nコンピュータの能力が限られている：本当に役に立つことを成し遂げるには、十分なメモリや処理速度がなかったのである。例えば、ロス・クイリアンの自然言語に関する成功した研究は、たった20語の語彙で実証されましたが、これはメモリに収まるのがそれしかなかったからです[106]。ハンス・モラベックは1976年に、コンピュータは知能を発揮するにはまだ数百万倍も弱すぎると主張しました。彼は、航空機が馬力を必要とするのと同じように、人工知能はコンピュータのパワーを必要とする、というアナロジーを提案した。コンピュータビジョンに関して、モラベックは、人間の網膜のエッジと動きの検出能力をリアルタイムでマッチングさせるには、109演算\/秒（1000MIPS）の汎用コンピュータが必要だと推定した[108]。2011年現在、コンピュータビジョンの実用化には1万から100万MIPSが必要とされている。これに対し、1976年当時最速のスーパーコンピュータであったCray-1（小売価格500万～800万ドル）は、約80～130MIPSの性能しかなく、当時の一般的なデスクトップコンピュータは1MIPS以下の性能しかありませんでした。\n難解さと組合せ爆発1972年、リチャード・カープは、1971年のスティーブン・クックの定理を基に、おそらく指数関数時間（入力の大きさ）でしか解けない問題が数多く存在することを示した。これらの問題の最適解を見つけるには、問題が些細な場合を除き、想像を絶する量のコンピュータ時間を必要とする。このことは、AIが使用する「おもちゃ」の解法の多くが、有用なシステムにスケールアップすることはないだろうということを、ほぼ確実に意味していた[109]。\nコモンセンスな知識と推論。視覚や自然言語のような重要な人工知能アプリケーションの多くは、単に世界に関する膨大な量の情報を必要とします：プログラムは、見ているものや話しているものについて何らかの考えを持つ必要があります。このため、プログラムは子供と同じように世界についてほとんど知っていなければなりません。研究者はすぐに、これが実に膨大な情報量であることを発見しました。1970年当時、これほど大規模なデータベースを構築できる人はおらず、プログラムがこれほど多くの情報を学習する方法を知る人もいなかった[110]。\nモラベックのパラドックス：定理の証明や幾何学の問題を解くことはコンピュータにとって比較的容易であるが、顔を認識したり、何もぶつからずに部屋を横断したりするような単純と思われるタスクは極めて困難である。このことは、1970年代半ばまでに視覚とロボット工学の研究がほとんど進展しなかったことの説明にもなっている[111]。\nフレームと資格の問題。論理を使うAI研究者（John McCarthyなど）は、論理自体の構造を変更しないと、計画や既定の推論を含む通常の推論を表現できないことを発見した。彼らはこの問題を解決するために新しい論理（非単調論理や様相論理など）を開発した[112]。\nファンディングの終わり\nこちらもご覧ください：AIの冬\nAI研究に資金を提供していた機関（英国政府、DARPA、NRCなど）は、進歩のなさに苛立ち、最終的にAIへの非直接的な研究への資金提供をほぼすべて打ち切った。このパターンは、機械翻訳の取り組みを批判するALPACレポートが登場した1966年に早くも始まっています。1973年、イギリスのAI研究の状況に関するライトヒル報告書は、AIがその「壮大な目的」を達成するのに全く失敗したと批判し、同国でのAI研究の解体につながった[113]。[114](報告書はAIの失敗の理由として、特に組み合わせ爆発問題に言及している)[115] DARPAはCMUの音声理解研究プログラムに取り組む研究者に深く失望し、年間300万ドルの助成を取り消した[116] 1974年までに、AIプロジェクトのための資金調達は困難なものとなっていた。\n\nハンス・モラヴェックは、この危機を同僚たちの非現実的な予測に起因するものとした。「多くの研究者が、誇張の度合いを増す網に巻き込まれていた」[117] しかし、もう一つ問題があった。1969年にマンスフィールド修正条項が成立して以来、DARPAは「基本的な非方向性研究よりも、ミッション指向の直接研究」に資金を提供するよう圧力を強めていた。60年代に行われた創造的で自由奔放な探査のための資金は、DARPAからは出てこないのである。その代わりに、自律型戦車や戦闘管理システムなど、明確な目的を持った特定のプロジェクトに資金が向けられることになった[118]。\n\n学内全域からの批評\nも参照してください：人工知能の哲学\nAI研究者の主張に対して、何人かの哲学者が強い異議を唱えた。最も早かったのはジョン・ルーカスで、ゲーデルの不完全性定理は、形式的なシステム（コンピュータプログラムなど）は特定の文の真理を見ることはできないが、人間にはできることを示したと主張した。[119] ヒューバート・ドレイファスは、1960年代の約束破りを揶揄し、AIの前提を批判し、人間の推論は実際にはほとんど「記号処理」を伴わず、多くの具象的、本能的、無意識的な「ノウハウ」を含んでいると主張した[120][121] 1980年に発表したジョン・サールの中国の部屋の議論は、プログラムはそれが使う記号（「意図性」という品質）を「理解」するとはいえないことを示そうとした。記号が機械にとって意味を持たないのであれば、機械は「思考」しているとは言えないとサールは主張した[122]。\n\nこれらの批判は、AI研究者たちに真剣に受け止められていませんでした。難解さや常識的な知識といった問題の方が、よほど身近で深刻に感じられたからだ。ノウハウ」や「意図性」が、実際のコンピュータプログラムにどのような違いをもたらすかは不明であった。ミンスキーはドレフュスとサールについて「彼らは誤解しており、無視されるべきだ」と述べた[123]。MITで教えていたドレフュスは冷遇され、後に彼はAI研究者が「私と昼食をとるところを見られることはないだろう」と述べた。\"124] ELIZAの著者であるジョセフ・ワイゼンバウムは、ドレイファスに対する同僚たちの扱いがプロフェッショナルではなく、幼稚であると感じた[125]。 彼はドレイファスの立場を率直に批判していたが、「彼らのは人間を扱う方法ではないことを意図的に明らかにした」[126]。\n\nワイゼンバウムは、ケネス・コルビーがELIZAをベースに「心理療法的な対話を行うことができるコンピュータプログラム」を書いたときから、AIに対して深刻な倫理的疑念を抱き始めた[127]。ワイゼンバウムは、コルビーが心ないプログラムを重大な治療ツールと見なしていることに心を痛めていた。確執が始まり、コルビーがプログラムへの貢献についてワイゼンバウムの功績を認めなかったため、状況は改善されなかった。1976年、ワイゼンバウムは『Computer Power and Human Reason』を出版し、人工知能の誤用は人間の命を粗末にする可能性があると主張した[128]。\n\nパーセプトロンとコネクショニズムへの攻撃\nパーセプトロンは、1958年にブロンクス高校でミンスキーと同級生だったフランク・ローゼンブラットによって発表されたニューラルネットワークの一種である。多くのAI研究者と同様、彼はその力を楽観視し、「パーセプトロンはいずれ学習、意思決定、言語翻訳ができるようになるかもしれない」と予言した。このパラダイムに関する活発な研究プログラムは1960年代を通して行われたが、ミンスキーとパパートの1969年の著書『パーセプトロン』の出版によって、突然停止したのである。パーセプトロンができることには大きな限界があり、フランク・ローゼンブラットの予測は大きく誇張されていたことが示唆されたのである。この本の効果は絶大で、10年間はコネクショニズムの研究は全く行われなかった。しかし、やがて新しい世代の研究者がこの分野を復活させ、以後は人工知能の重要かつ有用な一部となる。ローゼンブラットは、この本が出版された直後にボート事故で亡くなり、これを見届けることはできなかった[102]。\n\n論理と記号的推論：\"ニート \"たち\n1963年、J. Alan Robinsonは、コンピュータに演繹法を実装する簡単な方法、解決・統一アルゴリズムを発見した[129]。しかし、1960年代後半にマッカーシーとその学生によって試みられたような素直な実装は特に難解で、プログラムは簡単な定理を証明するのに天文学的な数のステップを必要とした。[1970年代、エジンバラ大学のロバート・コワルスキーによって、より実りある論理学へのアプローチが開発され、まもなくフランスの研究者アラン・コルメロアとフィリップ・ルーセルとの共同研究によって、成功した論理プログラミング言語Prologが作られた[131]。Prologでは、扱いやすい計算を可能にする論理のサブセット（Horn句、「規則」や「生産規則」に密接な関連がある）を使用している。ルールは、その後も影響力を持ち続け、エドワード・ファイゲンバウムのエキスパートシステムや、アレン・ニューウェルとハーバート・A・サイモンの継続的な研究により、ソアとその統一的な認知理論につながる基礎を提供することになる[132]。\n\n論理的アプローチの批判者たちは、ドレフュスがそうであったように、人間は問題を解決するときに論理を使うことはほとんどないと指摘した。ピーター・ワソン、エレノア・ロッシュ、エイモス・トヴェルスキー、ダニエル・カーネマンなどの心理学者による実験がその証拠である[133]。マッカーシーは、人が何をするかは関係ないと反論した。彼は、本当に必要なのは問題を解決できる機械であって、人と同じように考える機械ではないと主張した[134]。\n\nフレームとスクリプト：\"スカッフルズ\"\nマッカーシーのやり方を批判したのは、同じマサチューセッツ工科大学の同僚たちであった。マーヴィン・ミンスキー、シーモア・パパート、ロジャー・シャンクは、「物語理解」や「物体認識」のような、機械が人間のように考えることを必要とする問題を解決しようとしていた。椅子」や「レストラン」といった一般的な概念を使うためには、人間が通常行うのと同じような非論理的な仮定をしなければならなかったのです。残念ながら、このような不正確な概念は、論理的に表現することが難しい。ジェラルド・サスマンは、「本質的に不正確な概念を記述するために正確な言語を使用しても、それらをより正確にすることはできない」と観察した[135]。シャンクは、マッカーシー、コワルスキー、ファイゲンバウム、ニューウェル、サイモンが用いた「きちんとした」パラダイムに対して、彼らの「反論理」アプローチを「無精髭」と呼んだ[136]。\n\n1975年、ミンスキーは重要な論文の中で、彼の仲間の「無精者」研究者の多くが、同じ種類のツール、つまり、何かに関する私たちの常識的な仮定をすべて捕らえる枠組みを使っていると指摘しました。例えば、鳥という概念を使う場合、鳥は飛ぶ、虫を食べるなど、すぐに思いつく事実がある。しかし、このような構造化された仮定は、私たちが言ったり考えたりするすべての文脈の一部となっているのです。彼はこれらの構造を「フレーム」と呼んだ。シャンクは、彼が「スクリプト」と呼ぶフレームのバージョンを使って、英語の短編小説に関する質問にうまく答えることができた[137]。","output":"非現実的な期待、資金不足、重要な結果を出すことの難しさ、そして1970年代にAI科学者が克服できなかった多くの基本的な限界の発見が、この10年間のAI研究の衰退に貢献しました。","category":"closed_qa"}
