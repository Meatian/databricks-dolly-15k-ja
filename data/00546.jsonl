{"index":"546","instruction":"この要約から、ブライアン・クリスチャンが著書「アライメント・プロブレム」の3つのセクションで取り上げた、人工知能システムが人間の価値観とずれた行動を示す方法を3つ挙げてください。","input":"本書は、3つのセクションに分かれています：予言」「代理」「規範性」です。各セクションでは、人工知能と人間の価値観との整合性において、異なる課題に取り組む研究者や技術者を取り上げています。\n\n予言\n第1部では、人工知能研究の歴史、特にパーセプトロンやアレックスネットといった人工ニューラルネットワークの機械学習アプローチと、AIシステムがいかに意図しない振る舞いをするかという事例を織り交ぜて解説しています。ジュリア・アングウィンは、刑事被告人の再犯を予測するツールであるCOMPASアルゴリズムをProPublicaで調査した結果、その精度と特定の層への偏りが広く批判されるようになったジャーナリストの一人です。AIの主な調整課題の1つは、そのブラックボックス性（入力と出力は特定できるが、その間の変換プロセスは未確定）である。透明性がないため、システムがどこで正しく進み、どこで間違っているのかを知ることが困難です。\n\nエージェンシー\n第2部では、クリスチャンは同様に、行動主義やドーパミンといった報酬に関する心理学的研究の歴史と、AIシステムが価値関数（「どんな報酬や罰を期待するか」）を前にして方針（「何をするか」）を立てる必要がある強化学習のコンピュータ科学を織り交ぜて解説しています。彼は、DeepMind AlphaGoとAlphaZeroのシステムを \"おそらく自動カリキュラム設計における唯一で最も素晴らしい成果 \"と呼んでいます。また、強化学習者が外的報酬を専ら求めるのではなく、環境を探索しようと内発的に動機づけられる好奇心の重要性も強調しています。\n\n規範性\n第3章では、人間や機械の行動を模倣してAIを訓練する方法と、AIシステムの理想的な行動を示唆する可能性主義と現実主義といった哲学的な議論を取り上げます。特に重要なのは逆強化学習で、人間や他のエージェントの目的関数を機械が学習するための広範なアプローチである。クリスチャンは、効果的な利他主義と実存的リスクに関連する規範的課題について、哲学者のトビー・オードやウィリアム・マカスキルの研究を紹介し、アライメント問題をできるだけ効果的に乗り越えるための人間や機械の戦略を考案しようとしていることを述べている。","output":"最初のセクション「予言」では、予測モデルが検証困難な判断を下し、差別的・不公平になる可能性があることを語っている。\n\n第2章では、強化学習システムに関して、いくつかの顕著な成果があるにもかかわらず、ほぼ目的関数によって導かれ、世界を発見する好奇心によって導かれることはあまりない、と述べた。\n\n第3節の「規範性」では、逆強化学習技術が人間の目的関数を把握するという課題に直面する。","category":"summarization"}
