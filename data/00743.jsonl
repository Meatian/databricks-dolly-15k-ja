{"index":"743","instruction":"与えられた段落によると、畳み込みニューラルネットワークは、機械学習においてどのようにオーバーフィッティングを回避するのか。","input":"深層学習において、畳み込みニューラルネットワーク（CNN）は、視覚イメージの解析に最もよく適用される人工ニューラルネットワークの一種です。CNNは、少なくとも1つの層で、一般的な行列の乗算の代わりに畳み込みと呼ばれる数学的演算を使用します。CNNはピクセルデータを処理するために特別に設計されており、画像認識と処理に使用されます。画像・映像認識、レコメンダーシステム、画像分類、画像分割、医療画像解析、自然言語処理、ブレインコンピューターインターフェース、金融時系列などに応用されています。\n\nCNNは、シフト不変または空間不変人工ニューラルネットワーク（SIANN）とも呼ばれ、入力特徴に沿ってスライドする畳み込みカーネルまたはフィルタの共有重みアーキテクチャに基づき、特徴マップとして知られる翻訳等価な応答を提供します。直感に反して、ほとんどの畳み込みニューラルネットワークは、入力に適用されるダウンサンプリング操作のために、翻訳に対して不変ではありません。\n\nCNNは多層パーセプトロンの正則化バージョンである。多層パーセプトロンは通常、完全接続ネットワークであり、1つの層の各ニューロンは次の層のすべてのニューロンと接続されている。このようなネットワークは「完全接続」であるため、データをオーバーフィットさせる傾向があります。正則化、つまりオーバーフィットを防ぐ典型的な方法には、学習中のパラメータにペナルティを与える（ウェイト減衰など）、接続性を削る（スキップ接続、ドロップアウトなど）などがある。堅牢なデータセットを開発することで、CNNが、十分な数のデータセットが持つバイアスではなく、与えられたデータセットを特徴づける一般的な原理を学ぶ確率を高めることもできる。","output":"畳み込みニューラルネットワーク（CNN）は、各ニューロンが次の層のすべてのニューロンと接続されている完全接続層を持ち、この構造はオーバーフィッティングを避けるのに役立ちます。","category":"summarization"}
