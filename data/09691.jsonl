{"index":"9691","instruction":"さまざまな音声合成技術の長所と短所を抽出する。","input":"音声合成システムの最も重要な品質は、自然さと明瞭さである[28]。自然さは、出力が人間の音声にどれだけ近く聞こえるかを表し、明瞭さは、出力が理解されやすいかどうかを表している。理想的な音声合成装置は、自然さと明瞭さの両方を兼ね備えています。音声合成システムは通常、この2つの特性を最大化するように努めています。\n\n合成音声波形を生成する主な技術には、連結合成とフォルマント合成の2つがある。それぞれの技術には長所と短所があり、合成システムの使用目的によって、どちらの手法を使うかが決まるのが一般的です。\n\nコンカチネーションシンセシス\n主な記事コンカチネイティブシンセシス\n連結合成は、録音された音声のセグメントを連結（つなぎ合わせる）することに基づいています。一般に、連結合成は最も自然な響きの合成音声を生成する。しかし、音声の自然な変化と、波形を分割する自動化技術の性質の違いにより、出力に耳障りな不具合が生じることがあります。連結合成の主なサブタイプは3つあります。\n\nユニット選択合成\n単位選択合成は、録音された音声の大規模なデータベースを使用します。データベースを作成する際、録音された各発話は、個々の電話、二重電話、半音、音節、形態素、単語、フレーズ、文の一部または全部に分割されます。通常、セグメントへの分割は、波形やスペクトログラムなどの視覚的表現を使用して、「強制アライメント」モードに設定された特別に修正された音声認識装置を使用し、その後、いくつかの手動補正を行います[29]。次に、セグメント化と基本周波数（ピッチ）、時間、音節内の位置、近隣の電話などの音響パラメータに基づいて、音声データベース内のユニットのインデックスを作成します。実行時に、データベースから候補ユニットの最適な連鎖を決定することで、目的のターゲット発話が作成されます（ユニット選択）。このプロセスは、通常、特別に重み付けされた決定木を使用して実現されます。\n\nユニットセレクションは、録音された音声に少量のデジタル信号処理（DSP）を施すだけなので、最も自然な音声になります。DSPは、録音された音声をより自然に聞こえなくすることが多いのですが、一部のシステムでは、波形を滑らかにするために、連結の時点で少量の信号処理を行います。最高のユニット選択システムからの出力は、特にTTSシステムが調整された文脈では、実際の人間の声と見分けがつかないことがよくあります。しかし、最大限の自然さを得るためには、一般的に単位選択音声データベースが非常に大きくなる必要があり、システムによっては、数十時間分の音声を記録したギガバイト単位のデータも存在する[30]。また、単位選択アルゴリズムは、データベース内により良い選択肢が存在する場合でも、合成が理想的ではないところ（例えば、細かい言葉が不明瞭）からセグメントを選択することが知られている[31]。近年、研究者は、単位選択音声合成システムの不自然な部分を検出するさまざまな自動手法を提案している[32]。\n\nダイフォンの合成\nダイフォン合成は、ある言語で発生するすべてのダイフォン（音と音の遷移）を含む最小限の音声データベースを使用します。ダイフォンの数は言語のフォノタクトに依存し、例えばスペイン語には約800個のダイフォンがあり、ドイツ語には約2500個のダイフォンがあります。ダイフォン合成では、各ダイフォンの例は音声データベースに1つだけ含まれる。実行時に、線形予測符号化、PSOLA[33]、MBROLAなどのデジタル信号処理技術や、離散コサイン変換を使用したソースドメインでのピッチ修正などの最近の技術によって、文のターゲット韻律がこれらの最小単位に重ね合わされます[35] ダイフォン合成は、連結合成の音の不具合とフォルマント合成のロボットのように聞こえる性質を持っており、小さなサイズ以外にどちらのアプローチにもほとんど利点がない。そのため、商用アプリケーションでの使用は減少しているが[citation needed]、自由に利用できるソフトウェア実装が多数存在するため、研究での使用は続いている。ディフォン合成の初期の例は、マイケル・J・フリーマンが発明した教育ロボット、リーチムである[36]。リーチムには、授業カリキュラムに関する情報と、教えるようプログラムされた生徒の特定の経歴情報が含まれていた[37]。ニューヨーク州ブロンクスの4年生の教室でテストされた[38][39]。\n\nドメイン特異的な合成\n領域別合成は、あらかじめ記録された単語やフレーズを連結して、完全な発話を作成するものである。この技術は実装が非常に簡単で、しゃべる時計や計算機など、長い間商業的に使用されてきたものです[40]。文の種類が限られており、元の録音の韻律やイントネーションに近いため、これらのシステムの自然さのレベルは非常に高くすることができる[citation needed]。\n\nこれらのシステムは、データベース内の単語やフレーズに制限されているため、汎用性がなく、あらかじめプログラムされた単語やフレーズの組み合わせしか合成することができません。しかし、自然な話し言葉の中にある単語のブレンドは、多くのバリエーションを考慮しない限り、問題を引き起こす可能性があります。例えば、英語の非鼻声弁では、「clear」\/ˈklɪə\/のような単語の「r」は、通常、次の単語の最初の文字が母音の場合にのみ発音されます（例えば、「clear out」は\/ˌklɪəɹˈとして実現します）。同様にフランス語では、母音で始まる単語が続くと、多くの最終子音が無声化します（リエゾンと呼ばれる効果）。この交互作用は、単純な単語と単語の連結システムでは再現できず、文脈を考慮した複雑なシステムが必要になる。\n\nフォルマント合成\nフォルマント合成では、人間の音声サンプルを実行時に使用することはありません。その代わり、合成された音声出力は、加算合成と音響モデル（物理モデリング合成）を使って作成されます[41]。基本周波数、ボイシング、ノイズレベルなどのパラメータを時間と共に変化させ、人工音声の波形を作成します。この方法はルールベース合成と呼ばれることもあるが、多くの連結型システムはルールベースのコンポーネントも持っている。フォルマント合成技術に基づく多くのシステムは、人間の音声と見間違うことのない人工的でロボット的な音声を生成します。しかし、最大限の自然さが音声合成システムの目標であるとは限らず、フォルマント合成システムには連結システムよりも優れた点があります。フォルマント合成方式は、連結方式にありがちな音響的な不具合を回避し、超高速でも確実に聞き取れる音声にすることができます。高速合成音声は、視覚障害者がスクリーンリーダーを使ってコンピュータを素早く操作するために使用されます。フォルマントシンセサイザーは、音声サンプルのデータベースを持たないため、通常、連結型システムよりも小さなプログラムです。そのため、メモリやマイクロプロセッサの能力が特に制限される組み込みシステムで使用することができます。また、フォルマント方式は、出力される音声のすべてを制御できるため、質問や発言だけでなく、さまざまな感情や声のトーンなど、多様な韻律やイントネーションを出力することができる。\n\nフォルマント合成において、非リアルタイムでありながら高精度のイントネーション制御を実現した例として、1970年代後半にテキサス・インスツルメンツの玩具「スピーク＆スペル」で行われた作業や、1980年代前半にセガのアーケードマシン[42]、およびTMS5220 LPCチップを使用したアタリ社の多くのアーケードゲーム[43]があります。これらのプロジェクトで適切なイントネーションを作成するのは骨の折れる作業であり、その成果はリアルタイムの音声合成インターフェースにまだ及んでいない[44]。\n\nアーティキュレーション・シンセシス\n調音合成とは、人間の声道とそこで起こる調音過程のモデルに基づいて音声を合成する計算技術のことである。実験室で定期的に使用される最初の調音合成装置は、1970年代半ばにハスキンズ研究所でフィリップ・ルービン、トム・ベア、ポール・マーメルスタインによって開発されました。ASYとして知られるこのシンセサイザーは、1960年代から1970年代にかけてベル研究所でポール・マーメルスタイン、セシル・コーカーらによって開発された声道モデルに基づいている。\n\n最近まで、調音合成モデルは商用音声合成システムには組み込まれていませんでした。しかし、カルガリー大学のスピンオフ企業であるTrillium Sound Researchが開発し、販売したNeXTベースのシステムは例外であり、オリジナルの研究の多くがここで行われました。NeXT（1980年代後半にスティーブ・ジョブズによって設立され、1997年にアップルコンピュータと合併）の様々な形態の終焉後、TrilliumソフトウェアはGNU General Public Licenseの下で公開され、gnuspeechとして作業が継続されています。1994年に発売されたこのシステムは、カレの「特徴的な領域モデル」によって制御された人間の口腔と鼻腔の導波管または伝送線アナログを使用して、完全な調音ベースのテキストから音声への変換を行います。\n\nさらに最近のシンセサイザーは、Jorge C. Luceroらによって開発され、声帯のバイオメカニクス、声門の空気力学、気管支、鼻腔、口腔内の音響波伝播のモデルが組み込まれており、物理ベースの音声シミュレーションのフルシステムを構成している[45][46]。","output":"合成音声波形を生成する主な技術として、連結合成とフォルマント合成の2つがあります。\n\n連結合成は、録音された音声のセグメントをつなぎ合わせることに基づいています。一般に、最も自然な響きの合成音声を得ることができます。しかし、音声の自然な変化と、波形を分割するための自動化された技術の性質の違いにより、出力に耳障りな不具合が生じることがあります。自然な音声を得るためには、音声データベースが非常に大きくなる必要があり、システムによっては、数十時間分の音声を記録したギガバイト単位のデータも存在します。\n\nフォルマント合成は、実行時に人間の音声サンプルを使用しません。その代わり、合成された音声出力は、加算合成と音響モデルを使って作成されます。  フォルマント合成技術に基づく多くのシステムは、人間の音声と見間違うことのない、人工的でロボット風の音声を生成します。  また、音声サンプルのデータベースを持たないため、通常、連結型システムよりも小規模なプログラムとなっています。そのため、メモリやマイクロプロセッサの能力が特に制限される組み込みシステムで使用することができます。","category":"information_extraction"}
